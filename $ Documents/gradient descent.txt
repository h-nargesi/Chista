[cross-entropy loss]
Error = âˆ‘ yi * log(Å·i)

[errorest]
Error = Â½ * (y - Å·)Â²

[soft-max]
f(h) = e^h / âˆ‘ e^hi
ğ›› Æ’(hi) / ğ›› ha = 
if i = a => ğ›› Æ’(hi) / ğ›› ha = f(ha)(1 - f(ha))
if i != a => ğ›› Æ’(hi) / ğ›› ha = -f(hi)f(ha)

[weights change]
Î”wi = -(âˆ‚Error / âˆ‚wi)

[output layer]
e = (y - Å·)
Î´ = e * Æ’â€™(h)
Î”wi = Î· * Î´ * xi

[hidden layer]
(j=hidden layer, k=output layer)
ej = (âˆ‘k Î´k * wjk)
Î´j = ej * Æ’â€™(hj)
Î”wi = Î· * Î´ * xi