[cross-entropy loss]
Error = ∑ yi * log(ŷi)

[errorest]
Error = ½ * (y - ŷ)²

[soft-max]
f(h) = e^h / ∑ e^hi
𝛛 ƒ(hi) / 𝛛 ha = 
if i = a => 𝛛 ƒ(hi) / 𝛛 ha = f(ha)(1 - f(ha))
if i != a => 𝛛 ƒ(hi) / 𝛛 ha = -f(hi)f(ha)

[weights change]
Δwi = -(∂Error / ∂wi)

[output layer]
e = (y - ŷ)
δ = e * ƒ’(h)
Δwi = η * δ * xi

[hidden layer]
(j=hidden layer, k=output layer)
ej = (∑k δk * wjk)
δj = ej * ƒ’(hj)
Δwi = η * δ * xi